#!/usr/bin/env python3
"""Test script to verify data loading setup"""

import os
from pathlib import Path
import pandas as pd

def test_data_directory():
    """Check if .data directory and files exist"""
    data_dir = Path("./.data")
    
    if not data_dir.exists():
        print("âŒ .data directory not found!")
        return False
    
    print("âœ… .data directory found")
    
    # Check for required files
    required_files = [
        "merged_lawyers.csv",
        "lawyer_normalized_mapping.csv",
        "merged_lawyers_locations.csv",
        "merged_lawyers_source_data.csv",
        "googleplacesreview.csv",
        "perplexityreview.csv",
        "scorecardweights.csv"
    ]
    
    all_files_exist = True
    for file in required_files:
        file_path = data_dir / file
        if file_path.exists():
            size_mb = file_path.stat().st_size / (1024 * 1024)
            print(f"âœ… {file}: {size_mb:.2f} MB")
        else:
            print(f"âŒ {file}: NOT FOUND")
            all_files_exist = False
    
    return all_files_exist

def test_csv_loading():
    """Try loading a small sample from each CSV"""
    try:
        print("\nğŸ“Š Testing CSV loading...")
        
        # Test loading the scorecard weights (small file)
        scorecard_df = pd.read_csv("./.data/scorecardweights.csv", nrows=5)
        print(f"âœ… Scorecard weights loaded: {scorecard_df.shape[0]} rows, {scorecard_df.shape[1]} columns")
        
        # Test loading lawyers data (just headers)
        lawyers_df = pd.read_csv("./.data/merged_lawyers.csv", nrows=1)
        print(f"âœ… Merged lawyers columns: {list(lawyers_df.columns)[:5]}... ({len(lawyers_df.columns)} total)")
        
        return True
    except Exception as e:
        print(f"âŒ Error loading CSV: {e}")
        return False

def test_elasticsearch_connection():
    """Check if Elasticsearch is accessible"""
    import urllib.request
    import json
    
    try:
        print("\nğŸ” Testing Elasticsearch connection...")
        req = urllib.request.Request("http://localhost:9200")
        with urllib.request.urlopen(req) as response:
            data = json.loads(response.read())
            print(f"âœ… Elasticsearch {data['version']['number']} is running")
            return True
    except Exception as e:
        print(f"âŒ Elasticsearch not accessible: {e}")
        print("ğŸ’¡ Run ./start-elasticsearch.sh to start Elasticsearch")
        return False

def main():
    print("ğŸ”§ Testing LoveAndLaw data loading setup\n")
    
    # Run tests
    data_ok = test_data_directory()
    csv_ok = test_csv_loading() if data_ok else False
    es_ok = test_elasticsearch_connection()
    
    print("\nğŸ“‹ Summary:")
    print(f"  Data files: {'âœ… OK' if data_ok else 'âŒ FAILED'}")
    print(f"  CSV loading: {'âœ… OK' if csv_ok else 'âŒ FAILED'}")
    print(f"  Elasticsearch: {'âœ… OK' if es_ok else 'âŒ FAILED'}")
    
    if data_ok and csv_ok:
        print("\nâœ¨ Ready to load data!")
        print("Run: python scripts/load_lawyer_data.py")
    else:
        print("\nâš ï¸  Please fix the issues above before proceeding")

if __name__ == "__main__":
    main()